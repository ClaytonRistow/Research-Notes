\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=1in]{geometry}
\geometry{a4paper}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[mathscr]{euscript}
\usepackage{amsthm}

\title{Branch Node Asymptotics and the Grand Partition Function}
\author{Clayton Ristow}
\date{July 27 2015}

\begin{document}
\maketitle

Our next task is to apply our asymptotic techniques to our branch node counting series. These series had mulitvariate generating functions of the form
\begin{equation}
F(x,y)=\sum_{n=0}^\infty\sum_{b=0}^\infty F_{nb}x^ny^b
\end{equation}
We wish to treat this gerenating function as a single variate generating function so we will consolidate the like terms of x to and rewrite equation 1 as:
\begin{equation}
F(x,y)=\sum_{n=0}^\infty\left(\sum_{b=0}^\infty F_{nb}y^b\right)x^n
\end{equation}
To highlight this single variable quality we will rewrite our generating function using the following notations
\begin{equation}
F_y(x)\equiv\sum_{n=0}^\infty F_n(y)x^n =F(x,y)
\end{equation}
\begin{equation}
F_n(y) \equiv \sum_{b=0}^\infty F_{nb}y^b
\end{equation}
We can give some physical meaning to these new coefficients \(F_n(y)\). First we note that \(F_n(1)=F_n\) where \(F_n\) are the coefficients of the non-branch-node-counting series. We can begin to think of y as some sort of exponential weighting factor that is dependent on the number of branch nodes. It makes sence to interpret the value of y as the exponentiated energy that it takes to create a branch point. This energy is clearly the chemical potential of a branch point which we will call \(\mu_b\). Then we may make thermal interpretation of the value of y as the boltzmann weighted chemical potential which is a value called the fugocity. 
\begin{equation}
y=e^{\frac{\mu_b}{k_BT}}
\end{equation}
Clearly, y=1 corresponds to \(\mu_b=0\) meaning it takes no energy to create or remove a branch node which was an assumption we made when computing the partition function \(T_n\). 
These new coefficients \(F_n(y)\) are a generalization on on our non-branch-counting partition function \(F_n\). The number of branch nodes is not assumed to be fixed. Rather, we associate a chemical potential with the creation or destruction of a branch node. This means that \(F_n(y)\) is a Grand Partition Function in terms of the number of branch points. 

For convenience I will rewrite Thoerem 1 here:
\newtheorem{theorem}{Theorem}
\begin{theorem}
Let \(H(x,y(x))\) be a complex vauled function that is analytic in a neighborhood of \((x_0,G(x_0))\). If the following conditions are met:
\begin{enumerate}
\item \(H(x_0,G(x_0))=0\)
\item \(G(x)\) is analytic for \(|x|<|x_0|\) where \(x_0\) is the unique singularity of \(G(x)\)
\item \(G(x_0)=\sum_{n=0}^\infty G_nx_0^n\)
\item \(H(x,G(x))=0\) if \(|x|<|x_0|\)
\item \(\left.\frac{\partial H}{\partial {y(x)}}\right|_{(x_0,G(x_0))} = 0\)
\item \(\left.\frac{\partial^2 H}{\partial {y(x)}^2}\right|_{(x_0,G(x_0))} \neq 0\)
\end{enumerate}
Then
\[G(x)=G(x_0) + \sum_{k=1}^\infty a_k(x_0-x)^{\frac{k}{2}}\]
and if \(a_1 \neq 0\) then 
\[G_n \to \sqrt{ \frac{a_1^2x_0}{4\pi}}x_0^{-n}n^{\frac{-3}{2}}\]
or if \(a_1=0\) and \(a_3 \neq 0\) then 
\[G_n \to \sqrt{\frac{9a_3^2x_0^3}{16\pi}}x_0^{-n}n^{\frac{-5}{2}}\]
\end{theorem}

\section{Planted Trees}
We start our branch node asymptotic analysis with Planted trees. Before we apply the thoerem we must ensure that all 6 conditions are met. First will define the function \(H_y(x,z)\) to be
\begin{equation}
H_y(x,z)=x^2+xz+\frac{yz^2}{2}+\frac{yF_{y^2}(x^2)}{2}-z
\end{equation}
If we recall the functional equation for \(F_y(x)\):
\begin{equation}
F_y(x)=x^2+ xF_y(x)+\frac{y}{2}F_y^2(x)+\frac{y}{2}F_{y^2}(x^2)
\end{equation}
Then clearly \(z=F_y(x)\) is a solution to the equation \(H=0\) when \(F_y(x)\) converges. So if we can show that \(F_y(x)\) converges if \(|x| \leq x_0(y)\) for some value \(x_0(y)\) that is the radius of converge of \(F_y(x)\) then we will have shown that conditions 1, 2, 3, and 4 hold. 
	We will begin by showing that \(x_0(y)\) exists for all y. There are three possible cases: \(y<1 , y>1, y=1\). The \(y=1\) is trivial. We have shown that \(F_1(x)=F(x)\) and we showed previously that \(F(x)\) converges for all \(x \leq x_0=.4026975...\). The \(y<1\) is also quite simple. When \(y<1\) the \(F_{nb}y^b < F_{nb}\) so it follows that 
\[\sum_{b=0}^n F_{nb}y^b<\sum_{b=0}^n F_{nb}\] so we can conclude that 
\begin{equation}
F_n(y)<F_n \quad \text{ for all } n \, \text{ if } y<1
\end{equation}
So clearly \(F_y(x)\) will converge for \(x_0=.4026975...\) So. 
\begin{equation}
.4026975...\leq x_0(y) < 1 \quad \text{ if } y \leq 1
\end{equation} 
Thus \(x_0(y)\) exists for \(y \leq 1\)
Finally, we must deal with the y>1 case. First will will briefly show that if \(b \geq \frac{n}{2}\) then \(F_{nb}=0\). We will start by defining c to be the number of nodes with 2 branches and e to be the number of nodes with one branch (end nodes).Then clearly we may write for any tree.
\begin{equation}
b + c + e = n
\end{equation}
we can also note that whenever we add another branch point we nessessarily create another end point. Combining this observation with the fact that a tree with no branch points has two end points, we may wirte for all trees that. 
\begin{equation}
b + 2= e
\end{equation}
we may combine Eq. 10 and Eq. 11 to get
\begin{equation}
2b=n-c-2
\end{equation}
now we wish to maximize our branch point. To do this we can simply set \(c=0\) in Eq. 12 and then we get \(2b=n-2\) or more simply
\begin{equation}
b<\frac{n}{2}
\end{equation}
This means there are no trees where the number of branch points is \(\frac{n}{2}\) or higher. So we can conculde that if \(b \geq \frac{n}{2}\) then \(F_{nb}=0\).
now let us turn back to the case where \(y>1\) let us choose \(x=\frac{x_0}{y}\) where \(x_0 =.4026975\). Then
\begin{equation}
F_n(y)x^n=\left(\sum_{b=0}^nF_{nb}y^b\right)\left(\frac{x_0}{y}\right)^n
\end{equation}
But since \(F_{nb}=0\) if \(b \geq \frac{n}{2}\) we can write
\begin{equation}
F_n(y)x^n=\left(\sum_{b=0}^{n/2}F_{nb}y^b\right)\left(\frac{x_0}{y}\right)^n=\left(\sum_{b=0}^{n/2}F_{nb}y^{b-n}\right)x_0^n
\end{equation}
Then since \(b<\frac{n}{2}<n\) and y>1, it follows that \(y^{b-n}<1\) so 
\begin{equation}
\left(\sum_{b=0}^{n/2}F_{nb}y^{b-n}\right)x_0^n<F_nx_0^n
\end{equation}
Then by the comparison test \(F_y(\frac{x_0}{y})\) converges if \(y>1\). so we can conclude that
\begin{equation}
\frac{x_0}{y}\leq x_0(y) <1 \quad \text { if } y >1
\end{equation}
So we have finally shown that \(x_0(y)\) exists for all y. This shows that \(F_y(x)\) converges if \(x<x_0(y)\). It remains to show that \(F_y(x)\) converges at \(x=x_0(y)\). To show this we will show that 
\[\lim_{x \to x_0(y)^-}F_y(x) \; \text{exists}\]
Since the power series \(F_y(x)\) always has positive coefficents and positive powers of x, it is a monotonically increasing function so to show that this limit exists we must simply show that \(F_y(x)\) is bounded above. It follows from the functional equation that 
\[F_y(x)>\frac{y}{2}F_y^2(x)\]
Which then implies that 
\begin{equation}
\frac{2}{y}>F_y(x)
\end{equation}
thus \(F_y(x)\) is bounded above so the limit exists and therefore \(F_y(x_0(y))\) converges. 
Combining all of these results, we get that 
\begin{equation}
F_y(x) \, \text{ converges if } |x|\leq x_0(y)
\end{equation}
which shows that conditions 1, 2, 3, and 4 are all met. 

Condition 5 is shown using the same proof by contradiction using the Implicit Function Theorem that we used for the non-branch-node-counting series. Condition 6 is shown by differentiating Eq 6 with respect to z twice to get
\begin{equation}
\frac{\partial^2 H}{\partial z^2}=y
\end{equation}
If we think of y as the fugosicty (\(e^\frac{\mu_b}{k_BT}\)) it is clear that no possible values of \(\mu_b\) or \(T\) will result in a value of 0 for y so condition 6 holds.

Before we fully apply the theorem let us an expression for \(F_y(x_0(y))\). We can differentiate Eq. 6 and then apply condition 5 to get
\begin{equation}
0=x_0+yF_y(x_0(y))-1
\end{equation}
which can be rearraged to get
\begin{equation}
F_y(x_0(y))=\frac{1-x_0(y)}{y}
\end{equation}
Now we may apply Theorem 1 and expand \(F_y(x)\) as:
\begin{equation}
F_y(x)=F_y(x_0(y))+\sum_{k=1}^\infty a_k(x_0-x)^{k/2}
\end{equation}
Then if we differentiate this expansion we get:
\begin{equation}
F'_y(x)=-\sum_{k=1}^\infty \frac{ka_k}{2}(x_0-x)^{k/2-1}
\end{equation}
Then we may combine Eq. 23 and Eq. 24 to get:
\[F'_y(x)(F_y(x_0(y))-F_y(x))=\frac{a_1^2}{2}+\mathscr{O}(x_0-x)\]
Then if we take the limit as \(x \to x_0(y)\) we get that 
\begin{equation}
\lim_{x \to x_0(y)}F'_y(x)(F_y(x_0(y))-F_y(x))=\frac{a_1^2}{2}
\end{equation}
But we may also differentiate Eq. 7, plug in Eq. 22, and rearrange to get:
\begin{equation}
\lim_{x \to x_0(y)}F'_y(x)(F_y(x_0(y))-F_y(x))=\frac{2yx_0(y)+1-x_0(y)+x_0(y)y^2F'_{y^2}(x_0^2(y))}{y^2}
\end{equation}
Then we can combine Eq. 25 and Eq. 26 and solve for \(a_1\) to get
\begin{equation}
a_1=\frac{1}{y}\sqrt{2(1+x_0(y)(y^2F'_{y^2}(x_0^2(y))+2y-1))}
\end{equation}
So then by Theorem 1, we can write our asymptotic form as 
\begin{equation}
F_n(y) \approx \sqrt{\frac{x_0(y)+x_0^2(y)(y^2F'_{y^2}(x_0^2(y))+2y-1)}{2\pi y^2}} x_0^{-n}(y)n^{-3/2}
\end{equation}

There is still one problem. The method we used for findning the radius of convergence, taking the limit of the ration of the terms, takes 10,000 terms to get with in 3 decimal places of accuracy. Now that computing the coefficients involes a sum (see Eq. 4). so computing these coeffieients to very high n becomes unresonable. We need a way to find the radius of convergence of \(F_y(x)\) using as few terms as possible. Let us plug in \(x_0(y)\) for x in Eq. 6.
\[F_y(x_0(y))=x_0(y)^2+x_0(y)F_y(x_0(y))+\frac{y}{2}F_y^2(x_0(y))+\frac{y}{2}F_{y^2}(x_0^2(y))\]
And then we can substitute in Eq. 22 and reaarrange to get the following equation:
\begin{equation}
F_{y^2}(x_0^2(y))=\frac{1+2x_0(y)+(1-2y)x_0^2(y)}{y^2}
\end{equation}
We can use Mathematica to numerically solve this equation for \(x_0(y)\) and get more accurate answers by adding more terms on to the power series \(F_{y^2}(x_0^2(y))\). This method only requires 10 terms in the power series to get 6 decimal places of accuracy. This huge jump in accuracy is due to the fact \(x_0^2(y)\) is well inside the radius of convergence so we can get a very accurate estimate of \((F_{y^2}(x_0^2(y)\)) with just a few terms and by substituting Eq. 22 in we get an exact value for \(F_y(x_0(y))\). All of this results in a quick and easy method for finding \(x_0(y)\) for each y.

\section{General Trees} 
We now turn our attention to general trees. Again, we will use the notations
\begin{equation}
T_y(x)\equiv T(x,y) 
\end{equation}
\begin{equation}
T_n(y) \equiv \sum_{b=0}^\infty T_{nb}y^b
\end{equation}
to highlight the fact we will be treating the series as a single variable power series where the coeffiecients depend on y. We may write:
\begin{equation}
T_y(x) = \sum_{n=0}^\infty T_n(y)x^n
\end{equation}
 We must first confirm that \(T_y(x)\) meets all 6 nessessary conditions so we may apply Theorem 1. Let us first write \(H(x,z)\) as
\begin{equation}
H(x,z)=R_y(x)-\frac{F_y^2(x)}{2x^2}+\frac{F_{y^2}(x^2)}{2x^2}-z
\end{equation}
So clearly \(z=T_y(x)\) is a solution to \(H(x,z)=0\)whenever \(T_y(x)\) converges. Then conditions 1, 2, 3, and 4 will hold if we can show that for some \(x_T(y)\),\(T_y(x)\) converges for all \(x\leq x_T(y)\). 

The functional equation for \(T_y(x)\) is 
\begin{equation}
T_y(x)=R_y(x)-\frac{F_y^2(x)}{2x^2}+\frac{F_{y^2}(x^2)}{2x^2}
\end{equation}
Where \(R_y(x)\) is 
\begin{equation}
R_y(x)=x + F_y(x) +\frac{F_y(x)}{xy}-\frac{x}{y}-\frac{F_y(x)}{y}+\frac{yF_y^3(x)}{6x^2}+\frac{yF_{y^2}(x^2)F_y(x)}{2x^2}+\frac{yF_{y^3}(x^3)}{3x^2}
\end{equation}
And then we may combine the two to get 
\begin{equation}
T_y(x)=x + F_y(x) +\frac{F_y(x)}{xy}-\frac{x}{y}-\frac{F_y(x)}{y}+\frac{yF_y^3(x)}{6x^2}+\frac{yF_{y^2}(x^2)F_y(x)}{2x^2}+\frac{yF_{y^3}(x^3)}{3x^2}-\frac{F_y^2(x)}{2x^2}+\frac{F_{y^2}(x^2)}{2x^2}
\end{equation}
So we can think of \(T_y(x)\) as a function of \(x, F_y(x), F_{y^2}(x^2), \text{ and } F_{y^3}(x^3)\). This means that \(T_y(x)\) will converge whenever \(F_y(x), F_{y^2}(x^2), \text{ and } F_{y^3}(x^3)\) converge. \(F_y(x), F_{y^2}(x^2), \text{ and } F_{y^3}(x^3)\) have a radii of convergence of \(x_0(y),\sqrt{x_0(y^2)}, \text{ and } \sqrt[3]{x_0(y^3)}\) respectivly. So we observe that 
\[T_y(x) \text{ converges if } x \leq \text{min}\{x_0(y),\sqrt{x_0(y^2)}, \sqrt[3]{x_0(y^3)}\}\]
We will show that \(x_0(y)= \text{min}\{x_0(y),\sqrt{x_0(y^2)}, \sqrt[3]{x_0(y^3)}\}\). It follows easily fom the triangle inequality that 
\[\left(\sum_{b=0}^nF_{nb}y^b\right)^2 \geq \sum_{b=0}^nF_{nb}y^{2b}\]
Which we can write more compactly as 
\begin{equation}
F_n^2(y) \geq F_n(y^2) \quad \text{For all } n
\end{equation}
Then we consider the following two power series
\begin{equation}
P_1(x)=\sum_{n=0}^\infty F_n^2(y)x^n
\end{equation}
\begin{equation}
P_2(x)=\sum_{n=0}^\infty F_n(y^2)x^n
\end{equation}
Let thier radii of convergence be \(r_1\) and \(r_2\) respectively. Then because of Eq. 37 we may deduce that \(r_1\leq r_2\). but we may also write \(r_1\) and \(r_2\) as
\[r_1=\lim_{n \to \infty} \left(\frac{F_n^2(y)}{F_{n+1}^2(y)}\right)^2=x_0^2(y)\]
\[r_2=\lim_{n \to \infty} \frac{F_n(y^2)}{F_{n+1}(y^2)}=x_0(y^2)\]
So we may conclude that \(x_0^2(y) \leq x_0(y^2)\) or 
\begin{equation}
x_0(y) \leq \sqrt{x_0(y^2)}
\end{equation}
In a very similar way we can show 
\[x_0(y) \leq \sqrt[3]{x_0(y^3)}\]
so we can conclude that 
\[T_y(x) \text{ converges if } x \leq x_0(y)\]
and thus conditions 1, 2, 3, and 4 hold. Condition 5 holds Via the Inverse Function Theorem just as it did before and condition 6 holds as well. 
Then we may apply Theorem 1 and expand \(T_y(x)\) as
\begin{equation}
T_y(x)=T_y(x_0(y))+\sum_{k=1}^\infty b_k (x_0(y)-x)^{k/2}
\end{equation}
 Now we must find the value of \(b_1\). From differentiating the expansion we find
\begin{equation}
T_y'(x)=-\frac{b_1}{2}(x_0(y)-x)^{-1/2}-b_2-\frac{3b_3}{2}(x_0(y)-x0^{1/2}+...
\end{equation}
So as x gets close to \(x_0(y)\) all terms except the first two go to zero while the first term blows up. So close to \(x_0(y)\) the first term dominates the behavior of the function.
\begin{equation}
\lim_{x \to x_0(y)}T'_y(x) = -\frac{b_1}{2}(x_0(y)-x)^{-1/2}
\end{equation}
But, we may also differentiate Eq. 34 to get
\begin{align}
T_y'(x)=&1+F'_y(x)+\frac{F'_y(x)}{xy}-\frac{F_y(x)}{x^2y}-\frac{1}{y}-\frac{F'_y(x)}{y}+\frac{yF_y^2(x)F'_y(x)}{2x^2}-\frac{yF_y^3(x)}{3x^3}+\frac{yF_{y^2}(x^2)F'_y(x)}{2x^2}+\frac{yF'_{y^2}(x^2)F_y(x)}{x} \nonumber \\
&-\frac{yF_{y^2}(x^2)F_y(x)}{x^3}+ yF'_{y^3}(x^3)-\frac{2yF_{y^3}(x^3)}{3x^2}-\frac{yF_y(x)F'_y(x)}{x^2}+\frac{F_y^2(x)}{x^3}+\frac{F'_{y^2}(x^2)}{x}-\frac{F_{y^2}(x^2)}{x^3}
\end{align}  
Every term that does not have an \(F'_y(x)\) converges as \(x \to x_0(y)\) while every term that does blows up. So as x gets close to \(x_0(y)\) the behavior of the \(F'_y(x)\) terms dominate. So
\begin{equation}
\lim_{x \to x_0(y)} T'_y(x) =\lim_{x \to x_0(y)} F'_y(x)\left(1+\frac{1}{xy}-\frac{1}{y}+\frac{1}{x^2}\left(\frac{yF_y^2(x)}{2}+\frac{yF_{y^2}(x^2)}{2}-F_y(x)\right)\right)
\end{equation}
Then we may use Eq. 7, Eq.24 , and Eq. 43 to get
\[b_1=a_1\left(\frac{1}{x_0(y)y}-\frac{1}{y}-\frac{F_y(x_0(y))}{x_0}\right)\]
Which simplfies using Eq. 22 to 
\begin{equation}
b_1=0
\end{equation}
Since \(b_1=0\) we must find the value of \(b_3\) and use the second approximation to find our asymptotic formula. To do this we must take the second derivative of \(T_y(x)\). However, it is useful to use a few tricks to remove all of the \(F'_y(x)\) terms from Eq. 44 (we are able to do this because \(T'_y(x)\) converges at \(x_0(y)\)). Then when we differentiate  \(T'_y(x)\) we wont have any \(F''_y(x)\) terms so the only divergent terms will again be those with \(F'_y(x)\). Then when we take the limit as \(x \to x_0(y)\) we will not have a weird mix of \(F'_y(x)\) and \(F''_y(x)\) terms contributing to the behavior. So we recall that
\[T'_y(x) = F'_y(x)\left(\frac{1}{xy}-\frac{1}{y}-\frac{F_y(x)}{x}\right)+...\]
which can be simplified to 
\begin{equation}
T'_y(x) = \frac{F'_y(x)}{xy}(1-x-yF_y(x))+...
\end{equation}
Then, by differentiating Eq 7. we can show that 
\begin{equation}
F'_y(x)(1-x-yF_y(x))=2x+F_y(x)+xyF_{y^2}(x^2)
\end{equation}
Substituting this into Eq.47 and adding the rest of the terms in we get
\begin{align}
T_y'(x)=& \frac{2}{y}+\frac{F_y(x)}{xy}+F'_{y^2}(x^2)+1-\frac{F_y(x)}{x^2y}-\frac{1}{y}-\frac{yF_y^3(x)}{3x^3}+\frac{yF'_{y^2}(x^2)F_y(x)}{x} \nonumber \\
&-\frac{yF_{y^2}(x^2)F_y(x)}{x^3}+ yF'_{y^3}(x^3)-\frac{2yF_{y^3}(x^3)}{3x^2}+\frac{F_y^2(x)}{x^3}+\frac{F'_{y^2}(x^2)}{x}-\frac{F_{y^2}(x^2)}{x^3}
\end{align}  
Now we will take the second derivative of \(T_y(x)\). Eventually, we will take the limit as \(x \to x_0(y)\). Then, diveregent terms such as \(T''_y(x)\) and \(F'_y(x)\) will dominate. So when taking the derivative we only care about the terms with \(F'_y(x)\) so only those terms will be displayed in the interest in keeping the equation relitivly compact. We get
\begin{equation}
T''_y(x)=F'_y(x)\left(\frac{1}{xy}-\frac{1}{x^2y}+\frac{yF'_{y^2}(x^2)}{x}-\frac{yF_y^2(x)}{x^3}-\frac{yF_{y^2}(x^2)}{x^3}+\frac{2F_y(x)}{x^3}\right)+...
\end{equation}
Then we may take the limit as \(x \to x_0(y)\) and use Eq. 7 to simplify 
\begin{equation}
\lim_{x \to x_0(y)} T''_y(x)=\lim_{x \to x_0(y)}F'_y(x)\left(\frac{1}{x_0(y)y}-\frac{1}{x_0^2(y)y}+\frac{yF'_{y^2}(x_0^2(y))}{x}+\frac{1}{x^3}\bigg(2x_0^2(y)+2x_0(y)F_y(x_0(y))\bigg)\right)
\end{equation} 
which can be simplified further using Eq. 22 to get
\begin{equation}
\lim_{x \to x_0(y)} T''_y(x)=\lim_{x \to x_0(y)}F'_y(x)\left(\frac{2yx_0(y)+x_0(y)y^2F_{y^2}(x_0^2(y)+1-x_0(y)}{yx_0^2(y)}\right)
\end{equation}
And then we can differentiate Eq. 42 (remembering that \(b_1=0\)) and use Eq. 24 and Eq. 27 to get
\begin{equation}
\frac{3b_3}{4}=\left(\frac{a_1}{2}\right)\left(\frac{ya_1^2}{2x_0^2(y)}\right)
\end{equation}
which then gives us
\begin{equation}
b_3=\frac{ya_1^3}{3x_0^2(y)}
\end{equation}
So we get the following approximation for \(T_n(y)\) using Theorem 1
\begin{equation}
T_n(y) \approx \frac{ya_1^3}{4\sqrt{\pi x_0(y)}}x_0^{-n}(y)n^{-5/2} \quad \text{ where }a_1=\frac{1}{y}\sqrt{2(1+x_0(y)(y^2F'_{y^2}(x_0^2(y))+2y-1))}
\end{equation}
Or, if we let \(\alpha = \frac{a_1}{2}\sqrt{\frac{x_0(y)}{\pi}}\) which was our coefficient from the asymptotic expansion of planted trees we can equivalently write
\begin{equation}
T_n(y) \approx \frac{2\pi y \alpha^3}{x_0^2(y)}x_0^{-n}(y)n^{-5/2}
\end{equation}

\section{Grand Partition Function}
We have already stated that the coefficients we just approximated \(T_n(y)\) generalize our former approximation for \(T_n\) as a partition function for an annealed branched polymer of n nodes into both a a partition function for n nodes into a grand partition function on branch points by associating a fugocity, y, with the creation/destruction of a branch node. We have just completed an approximation for this mixed partition function in the form of Eq. 56. But we may go even further. Let us consider using Eq. 56 to write an approximate form of \(T_y(x)\).
\begin{equation}
T_y(x)=\sum_{n=0}^\infty  \frac{2\pi y \alpha^3}{x_0^2(y)}n^{-5/2} \left(\frac{x}{x_0(y)}\right)^n
\end{equation}
We can imagine that the eginnumber of nodes on a polymer is not fixed. physically this can be thought of as polymers splitting or combining to form smaller or larger polymers (this does actually happen). Then we may associate another chemical potential, \(\mu_n\), with the splitting or recombining of the polymers. Then using the same logic we used for the branch nodes we can think of x as the fugocity of splitting/recombination
\begin{equation}
x=e^{\frac{\mu_n}{k_BT}}
\end{equation}
Then \(T_y(x)\) becomes a grand partition function for both branch nodes and total nodes.
\begin{equation}
\Xi(\mu_b,\mu_n)=T_y(x)=\sum_{n=0}^\infty  \frac{2\pi y \alpha^3}{x_0^2(y)}n^{-5/2} \left(\frac{x}{x_0(y)}\right)^n \quad \text{where } x=e^{\beta \mu_n}\text{, } y=e^{\beta \mu_b}\text{, and  } \beta=\frac{1}{k_BT}
\end{equation}

\section{Free Energy and Thermal Average Branch Points}
Now that we have the partition function we can use it to get some results. Our partition function may be written as 
\begin{equation}
Z(\mu, n, T)=e^{-\beta E_0}  \frac{ya_1^3}{4\sqrt{\pi x_0(y)}}x_0^{-n}(y)n^{-5/2} \quad \text{where } y=e^{\beta \mu}
\end{equation}
The Grand Potential, a type of free energy can be computed from the partition function using the relation
\begin{equation}
\Phi(\mu, n , T)=\frac{-\ln(Z)}{\beta}
\end{equation}
Then applying Eq. 61 to Eq. 60 we get
\begin{equation}
\Phi(\mu,n,T)=E_0-\mu+k_BT\left((n+\frac{1}{2})\ln(x_0(y))+\frac{5}{2}\ln(n)+\ln(4\sqrt{\pi})-3\ln(a_1(y))\right)
\end{equation}
This is the free energy associated with our branch counting model of the polymer. It is a Grand Potential interms of branch points and a Helmholtz Free Energy in terms of n making it a mixed potential. From this mixed potential we can get all sorts of useful things. One such thing is a Thermal average of the branch points, \(\langle b\rangle\) which can be found by differentiating the mixed potential with respect to the chemical potential of a branch point. 
\begin{equation}
\langle b\rangle =-\frac{\partial \Phi}{\partial \mu}
\end{equation}
By applying Eq. 63 to Eq. 62 we can get and expression for the average branch points. We get
\begin{equation}
\langle b\rangle =1+\frac{1}{\beta}\left( 3\frac{\partial}{\partial \mu}\ln(a_1(y))-(n+\frac{1}{2})\frac{\partial}{\partial \mu} \ln(x_0(y))\right)
\end{equation}which can be simplified using the chain rule as:
\begin{equation}
\langle b\rangle =1+\frac{1}{\beta}\left( \frac{3}{a_1(y)}\frac{\partial a_1(y)}{\partial y}\frac{\partial y}{\partial \mu}-\frac{(n+\frac{1}{2})}{x_0(y)}\frac{\partial x_0(y)}{\partial y}\frac{\partial y}{\partial \mu} \right)
\end{equation}
Then we recall that \(y=e^{\beta \mu}\) so \[\frac{\partial y}{\partial \mu}=\beta y\] which allows us to simplify Eq. 65 to 
\begin{equation}
\langle b\rangle =1+ \frac{3y}{a_1(y)}\frac{\partial a_1(y)}{\partial y}-\frac{y(n+\frac{1}{2})}{x_0(y)}\frac{\partial x_0(y)}{\partial y}
\end{equation}
We can easily compute \(\frac{\partial x_0(y)}{\partial y}\) numerically using mathematica. All that remains is to calculate \(\frac{\partial a_1(y)}{\partial y}\). First let us realize that \(a_1(y)\) is most easily expressed as a function of y and \(x_0(y)\). Then \(\frac{\partial a_1(y)}{\partial y}\) may be calculated using the chain rule as:
\[\frac{\partial a_1(y,x_0)}{\partial y}=\frac{\partial x_0}{\partial y}\left(\frac{\partial a_1(y,x_0)}{\partial x_0}\right)_y+\left(\frac{\partial a_1(y,x_0)}{\partial y}\right)_{x_0}\]
For the time being, we will write \(x_0\) rather than \(x_0(y)\) becuase we will be treating it as a variable rather than a function.
then let us define the differential operator 
\begin{equation}
\partial_y \equiv \frac{\partial x_0}{\partial y}\left(\frac{\partial }{\partial x_0}\right)_y+\left(\frac{\partial}{\partial y}\right)_{x_0}
\end{equation}
Now let us rewrite Eq. 27 as 
\begin{equation}
\frac{a_1^2}{2x_0}-\frac{1}{x_0y^2}-\frac{2}{y}+\frac{1}{y^2}=F'_{y^2}(x_0^2)
\end{equation}
Then if we apply \(\partial_y\) to both sides we get
\begin{equation}
\frac{a_1}{x_0}\partial_y a_1-\frac{a_1^2}{2x_0^2}\frac{\partial x_0}{\partial y}+\frac{1}{y^2x_0^2}\frac{\partial x_0}{\partial y}+\frac{2}{x_0y^3}+\frac{2}{y^2}-\frac{2}{y^3}=\partial_yF'_{y^2}(x_0^2)
\end{equation}
Then solving for \(\partial_y a_1\) we get
\begin{equation}
\partial_y a_1=\frac{\partial x_0}{\partial y}\left(\frac{a_1}{2x_0}-\frac{1}{y^2x_0a_1}\right) +\frac{2}{a_1y^3}((1-y)x_0-1)+\frac{x_0}{a_1}\partial_y F'_{y^2}(x_0^2)
\end{equation}
But then the question becomes what is \(\partial_y F'_{y^2}(x_0^2)\). If we differentiate Eq 1 and substitute in \(x_0^2\) for x and \(y^2\) for y, we get that 
\begin{equation}
F'_{y^2}(x_0^2)=\sum_{n=0}^\infty\sum_{b=0}^\infty F_{nb}y^{2b}nx_0^{2n-2}
\end{equation}
Then after applying \(\partial_y\) to Eq. 71 we get
\begin{equation}
\partial_yF'_{y^2}(x_0^2)=\frac{\partial x_0}{\partial y}\sum_{n=0}^\infty\sum_{b=0}^\infty F_{nb}y^{2b}(2n^2-2n)x_0^{2n-3}+\sum_{n=0}^\infty\sum_{b=0}^\infty F_{nb}2by^{2b-1}nx_0^{2n-2}
\end{equation}
which simplfies to 
\begin{equation}
\partial_yF'_{y^2}(x_0^2)=\sum_{n=0}^\infty\sum_{b=0}^\infty F_{nb}y^{2b}\left(\frac{2bn}{y}+\frac{\partial x_0}{\partial y}\frac{2n^2-2n}{x_0} \right)x_0^{2n-2}
\end{equation}
Then we may write that 
\begin{equation}
\partial_yF'_{y^2}(x_0^2)=\Gamma(y) \quad \text{where } \Gamma(y) \equiv \sum_{n=0}^\infty \gamma_n(y)x_0^{2n-2} \; \text{and } \gamma_n(y) \equiv \sum_{b=0}^\infty F_{nb}y^{2b}\left(\frac{2bn}{y}+\frac{\partial x_0}{\partial y}\frac{2n^2-2n}{x_0} \right)
\end{equation}
Then using Eq. 74 we may rewrite Eq. 70 and plug it into Eq. 66 to get
\begin{equation}
\langle b\rangle = 1+ \frac{3y}{a_1}\left(\frac{\partial x_0}{\partial y}\left(\frac{a_1}{2x_0}-\frac{1}{y^2x_0a_1}\right) +\frac{2}{a_1y^3}((1-y)x_0-1)+\frac{x_0}{a_1}\Gamma(y)\right)-\frac{y(n+\frac{1}{2})}{x_0(y)}\frac{\partial x_0(y)}{\partial y}
\end{equation}
which simplifies to 
\begin{equation}
\langle b\rangle = 1-\frac{\partial x_0(y)}{\partial y}\frac{3}{yx_0a_1^2} +\frac{6}{a_1^2y^2}((1-y)x_0-1)+\frac{3x_0y}{a_1^2}\Gamma(y)-\frac{y(n-1)}{x_0(y)}\frac{\partial x_0(y)}{\partial y}
\end{equation}
Then notice if we define
\begin{equation}
A(\mu) \equiv -\frac{y}{x_0(y)}\frac{\partial x_0(y)}{\partial y}
\end{equation}
and
\begin{equation}
B(\mu) \equiv 1-A(\mu) -\frac{3}{yx_0(y)a_1^2(y)}\frac{\partial x_0(y)}{\partial y}++\frac{6}{a_1^2(y)y^2}((1-y)x_0(y)-1)+\frac{3x_0(y)y}{a_1^2(y)}\Gamma(y)
\end{equation}
We can rewrite Eq. 76 as 
\begin{equation}
\langle b\rangle = A(\mu)n+B(\mu)
\end{equation}
which reduces the expression for \(\langle b\rangle\) to a linear equation in terms of n where the coefficient depends on \(\mu\). Additionally, it turns out that \(B(\mu)\) is always on the order of single digits so since we are already deling with large n, we can ignore the \(B(\mu)\) term. So then Eq. 76 may be written as 
\begin{equation}
\frac{\langle b\rangle}{n}=A(\mu)
\end{equation}
This shows that, for a fixed value of \(\mu\), the ratio of average branch points to total points is roughly a constant!
\end{document}